{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading atlas, time series and threshold\n",
    "_, _, atlas_labels, n_ROIs = f.gen_atlas_labels()\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a dictionnary associating patient id and it's time series data\n",
    "full_df = pd.read_csv('ADNI_full/full_df.csv')\n",
    "patient_time_series_dict = {}\n",
    "\n",
    "for index, row in full_df.iterrows():\n",
    "    patient_id = row['Patient_id']\n",
    "    time_series = row['Time_series']\n",
    "    patient_time_series_dict[patient_id] = time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to save hypergraphs\n",
    "def save_hypergraph(hypergraph, directory, method, threshold, id):\n",
    "    dir = f'{directory}/{method}/thresh_{threshold}'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    np.savetxt(f'{dir}/{id}_{method}_{threshold}.csv', hypergraph, delimiter=',')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Fourier Clustering Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient 130_S_4883\n",
      "Processing patient 100_S_5091\n",
      "Processing patient 019_S_4549\n",
      "Processing patient 002_S_4473\n",
      "Processing patient 006_S_4546\n",
      "Processing patient 018_S_4257\n",
      "Processing patient 013_S_2389\n",
      "Processing patient 019_S_4367\n",
      "Processing patient 018_S_4733\n",
      "Processing patient 018_S_2155\n",
      "Processing patient 031_S_4590\n",
      "Processing patient 136_S_4269\n",
      "Processing patient 019_S_4548\n",
      "Processing patient 031_S_4194\n",
      "Processing patient 010_S_4442\n",
      "Processing patient 131_S_5138\n",
      "Processing patient 006_S_4357\n",
      "Processing patient 012_S_4026\n",
      "Processing patient 130_S_5142\n",
      "Processing patient 018_S_2180\n",
      "Processing patient 002_S_4262\n",
      "Processing patient 136_S_0186\n",
      "Processing patient 031_S_4021\n",
      "Processing patient 006_S_4960\n",
      "Processing patient 053_S_4578\n",
      "Processing patient 129_S_4073\n",
      "Processing patient 018_S_4889\n",
      "Processing patient 006_S_4150\n",
      "Processing patient 053_S_5070\n",
      "Processing patient 018_S_4696\n",
      "Processing patient 053_S_5272\n",
      "Processing patient 002_S_1280\n",
      "Processing patient 006_S_4346\n",
      "Processing patient 002_S_2010\n",
      "Processing patient 031_S_4024\n",
      "Processing patient 130_S_2403\n",
      "Processing patient 002_S_5178\n",
      "Processing patient 002_S_5018\n",
      "Processing patient 100_S_5280\n",
      "Processing patient 100_S_5096\n",
      "Processing patient 006_S_4192\n",
      "Processing patient 130_S_4660\n",
      "Processing patient 006_S_4153\n",
      "Processing patient 002_S_5230\n",
      "Processing patient 002_S_1268\n",
      "Processing patient 006_S_0731\n",
      "Processing patient 019_S_4835\n",
      "Processing patient 019_S_5242\n",
      "Processing patient 002_S_4270\n",
      "Processing patient 002_S_4264\n",
      "Processing patient 130_S_2373\n",
      "Processing patient 053_S_4557\n",
      "Processing patient 130_S_4925\n",
      "Processing patient 031_S_4032\n",
      "Processing patient 031_S_4218\n",
      "Processing patient 053_S_4813\n",
      "Processing patient 002_S_0413\n",
      "Processing patient 012_S_4545\n",
      "Processing patient 002_S_5256\n",
      "Processing patient 002_S_4799\n",
      "Processing patient 019_S_4477\n",
      "Processing patient 013_S_5137\n",
      "Processing patient 053_S_2357\n",
      "Processing patient 053_S_5202\n",
      "Processing patient 129_S_4371\n",
      "Processing patient 130_S_4605\n",
      "Processing patient 010_S_4345\n",
      "Processing patient 130_S_4405\n",
      "Processing patient 041_S_5026\n",
      "Processing patient 006_S_4485\n",
      "Processing patient 012_S_5213\n",
      "Processing patient 053_S_2396\n",
      "Processing patient 002_S_4229\n",
      "Processing patient 012_S_4643\n",
      "Processing patient 002_S_0729\n",
      "Processing patient 130_S_4997\n",
      "Processing patient 031_S_4042\n",
      "Processing patient 013_S_1186\n",
      "Processing patient 019_S_5019\n",
      "Processing patient 130_S_4982\n",
      "Processing patient 136_S_4433\n",
      "Processing patient 031_S_2022\n",
      "Processing patient 018_S_5262\n",
      "Processing patient 006_S_4679\n",
      "Processing patient 131_S_5148\n",
      "Processing patient 013_S_4616\n",
      "Processing patient 002_S_2073\n",
      "Processing patient 012_S_4849\n",
      "Processing patient 018_S_4597\n",
      "Processing patient 031_S_4721\n",
      "Processing patient 100_S_4512\n",
      "Processing patient 130_S_4415\n",
      "Processing patient 006_S_4867\n",
      "Processing patient 031_S_2233\n",
      "Processing patient 002_S_4171\n",
      "Processing patient 012_S_4094\n",
      "Processing patient 130_S_4417\n",
      "Processing patient 136_S_4408\n",
      "Processing patient 002_S_4213\n",
      "Processing patient 002_S_1155\n",
      "Processing patient 013_S_4985\n",
      "Processing patient 130_S_4984\n",
      "Processing patient 130_S_4990\n",
      "Processing patient 130_S_4589\n",
      "Processing patient 018_S_2133\n",
      "Processing patient 031_S_4496\n",
      "Processing patient 031_S_2018\n",
      "Processing patient 018_S_4349\n",
      "Processing patient 002_S_4237\n",
      "Processing patient 019_S_5012\n",
      "Processing patient 002_S_4746\n",
      "Processing patient 006_S_4713\n",
      "Processing patient 129_S_4422\n",
      "Processing patient 130_S_4817\n",
      "Processing patient 018_S_5240\n",
      "Processing patient 100_S_4469\n",
      "Processing patient 019_S_4293\n",
      "Processing patient 019_S_4285\n",
      "Processing patient 018_S_4809\n",
      "Processing patient 019_S_4252\n",
      "Processing patient 013_S_4395\n",
      "Processing patient 002_S_2043\n",
      "Processing patient 136_S_0107\n",
      "Processing patient 013_S_4791\n",
      "Processing patient 136_S_4189\n",
      "Processing patient 013_S_4579\n",
      "Processing patient 100_S_2351\n",
      "Processing patient 019_S_4680\n",
      "Processing patient 130_S_4343\n",
      "Processing patient 053_S_5208\n",
      "Processing patient 130_S_5059\n",
      "Processing patient 031_S_4476\n",
      "Processing patient 013_S_5071\n",
      "Processing patient 002_S_4219\n",
      "Processing patient 002_S_4225\n",
      "Processing patient 018_S_2138\n",
      "Processing patient 130_S_4971\n",
      "Processing patient 012_S_4128\n",
      "Processing patient 006_S_5153\n",
      "Processing patient 018_S_4400\n",
      "Processing patient 053_S_4661\n",
      "Processing patient 018_S_4399\n",
      "Processing patient 130_S_4352\n",
      "Processing patient 136_S_4993\n",
      "Processing patient 130_S_5258\n",
      "Processing patient 012_S_5195\n",
      "Processing patient 018_S_5250\n",
      "Processing patient 002_S_0685\n",
      "Processing patient 006_S_4449\n",
      "Processing patient 006_S_4515\n",
      "Processing patient 130_S_4542\n",
      "Processing patient 013_S_4595\n",
      "Processing patient 002_S_0295\n",
      "Processing patient 129_S_4220\n",
      "Processing patient 013_S_2324\n",
      "Processing patient 013_S_4580\n",
      "Processing patient 031_S_4474\n",
      "Processing patient 129_S_4369\n",
      "Processing patient 012_S_5157\n",
      "Processing patient 129_S_4396\n",
      "Processing patient 053_S_5296\n",
      "Processing patient 100_S_5106\n",
      "Processing patient 100_S_4556\n",
      "Processing patient 130_S_4294\n",
      "Processing patient 130_S_5175\n",
      "Processing patient 012_S_4987\n",
      "Processing patient 002_S_4447\n",
      "Processing patient 018_S_4868\n",
      "Processing patient 053_S_0919\n",
      "Processing patient 129_S_0778\n",
      "Processing patient 130_S_4730\n",
      "Processing patient 013_S_4917\n",
      "Processing patient 129_S_4287\n",
      "Processing patient 031_S_4029\n",
      "Processing patient 013_S_4268\n",
      "Processing patient 031_S_4203\n",
      "Processing patient 012_S_4012\n",
      "Processing patient 006_S_4363\n",
      "Processing patient 031_S_4149\n",
      "Processing patient 130_S_5006\n",
      "Processing patient 130_S_4250\n",
      "Processing patient 031_S_4005\n",
      "Processing patient 002_S_4521\n",
      "Processing patient 012_S_4188\n",
      "Processing patient 130_S_4641\n",
      "Processing patient 012_S_5121\n",
      "Processing patient 053_S_5287\n",
      "Processing patient 018_S_4313\n",
      "Processing patient 002_S_1261\n",
      "Processing patient 013_S_5171\n",
      "Processing patient 002_S_4251\n",
      "Processing patient 100_S_5102\n",
      "Processing patient 031_S_4947\n",
      "Processing patient 130_S_2391\n",
      "Processing patient 130_S_4468\n",
      "Processing patient 136_S_4517\n",
      "Processing patient 002_S_4654\n"
     ]
    }
   ],
   "source": [
    "# Iterating through each time series file to generate hypergraphs\n",
    "\n",
    "time_series_folder = 'ADNI_full/time_series'\n",
    "for file_name in os.listdir(time_series_folder):\n",
    "    \n",
    "    patient_id = file_name[3:13]\n",
    "    print(f'Processing patient {patient_id}')\n",
    "\n",
    "    # Loading the time series data and saving as a DataFrame\n",
    "    time_series_data = np.loadtxt(f'{time_series_folder}/{file_name}', delimiter=',')\n",
    "    time_series_df = pd.DataFrame(time_series_data, columns=atlas_labels)\n",
    "    \n",
    "    # Computing the correlation and dissimilarity matrices\n",
    "    correlation_matrix = time_series_df.corr().values\n",
    "    dissimilarity_matrix = 1 - np.abs(correlation_matrix)\n",
    "    dissimilarity_matrix[np.isnan(dissimilarity_matrix)] = 0\n",
    "    \n",
    "    # Performing hierarchical clustering using complete linkage method\n",
    "    linkage_matrix = linkage(squareform(dissimilarity_matrix), method='complete')\n",
    "    \n",
    "    # Assigning cluster indices to each ROI based on the threshold then generating a hypergraph based on the cluster indices\n",
    "    cluster_indices = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "    hypergraph = np.zeros((n_ROIs, n_ROIs))\n",
    "    for row_idx in range(n_ROIs):\n",
    "        for col_idx in range(n_ROIs):\n",
    "            if cluster_indices[row_idx] == cluster_indices[col_idx]:\n",
    "                hypergraph[row_idx, col_idx] = 1\n",
    "    \n",
    "    # Saving the hypergraph to a CSV file\n",
    "    save_hypergraph(hypergraph, 'Raw_to_Hypergraph', 'fourier_cluster', threshold, patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ElasticNet Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# From elastic_net.ipynb \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcvxpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "# From elastic_net.ipynb \n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def loss_fn(x_m, a_m, alpha_m):\n",
    "    return cp.norm2(x_m - cp.matmul(a_m, alpha_m))**2\n",
    "\n",
    "def regularizer_1(alpha_m):\n",
    "    return cp.norm1(alpha_m)\n",
    "\n",
    "def regularizer_2(alpha_m):\n",
    "    return cp.norm2(alpha_m)\n",
    "\n",
    "def objective_fn(x_m, a_m, alpha_m, lambd_1, lambd_2):\n",
    "    return loss_fn(x_m, a_m, alpha_m) + lambd_1 * regularizer_1(alpha_m) + lambd_2 * (regularizer_2(alpha_m) ** 2)\n",
    "\n",
    "def mse(x_m, a_m, alpha_m):\n",
    "    return (1.0 / a_m.shape[0]) * loss_fn(x_m, a_m, alpha_m).value\n",
    "\n",
    "def gen_mtrx(A , i):\n",
    "    dims = A.shape\n",
    "    A_m = np.copy(A)\n",
    "    X_m = np.copy(A[: , i])\n",
    "    zeros = np.zeros(dims[0])\n",
    "    A_m[: , i] = zeros\n",
    "    return X_m , A_m\n",
    "\n",
    "def couple_coeff(X_m,A_m,lambd_1,lambd_2):\n",
    "    alpha_m = cp.Variable(A_m.shape[1])\n",
    "    problem = cp.Problem(cp.Minimize(objective_fn(X_m, A_m, alpha_m, lambd_1, lambd_2)))\n",
    "    problem.solve()\n",
    "    return alpha_m.value[np.newaxis].T\n",
    "\n",
    "def test_lambd_1(X_train, A_train, X_test, A_test):\n",
    "    alpha_m = cp.Variable(A_train.shape[1])\n",
    "    lambd_1 = cp.Parameter(nonneg=True)\n",
    "    lambd_1_values = np.logspace(-2, 3, 50)\n",
    "    problem = cp.Problem(cp.Minimize(objective_fn(X_train , A_train , alpha_m , lambd_1)))\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    alpha_values = []\n",
    "\n",
    "    for v in lambd_1_values:\n",
    "        lambd_1.value = v\n",
    "        problem.solve()\n",
    "        train_errors.append(mse(X_train, A_train, alpha_m))\n",
    "        test_errors.append(mse(X_test, A_test, alpha_m))\n",
    "        alpha_values.append(alpha_m.value)\n",
    "    return train_errors, test_errors, lambd_1_values\n",
    "\n",
    "def test_lambd_2(X_train, A_train, X_test, A_test, lambd_1):\n",
    "    alpha_m = cp.Variable(A_train.shape[1])\n",
    "    lambd_2 = cp.Parameter(nonneg=True)\n",
    "    lambd_2_values = np.logspace(-2, 3, 50)\n",
    "    problem = cp.Problem(cp.Minimize(objective_fn(X_train , A_train , alpha_m , lambd_1, lambd_2)))\n",
    "\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    alpha_values = []\n",
    "\n",
    "    for v in lambd_2_values:\n",
    "        lambd_2.value = v\n",
    "        problem.solve()\n",
    "        train_errors.append(mse(X_train, A_train, alpha_m))\n",
    "        test_errors.append(mse(X_test, A_test, alpha_m))\n",
    "        alpha_values.append(alpha_m.value)\n",
    "    return train_errors, test_errors, lambd_2_values\n",
    "\n",
    "def plot_train_test_errors(train_errors, test_errors, lambd_2_values):\n",
    "    plt.plot(lambd_2_values, train_errors, label=\"Train error\")\n",
    "    plt.plot(lambd_2_values, test_errors, label=\"Test error\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel(r\"$\\lambda_{2}$\", fontsize=16)\n",
    "    plt.title(\"Mean Squared Error (MSE)\")\n",
    "    plt.show()\n",
    "\n",
    "def time_series_loader(root):\n",
    "    ts_list = sorted(os.listdir(root))\n",
    "    ts_path_list = []\n",
    "    for i in range(0, len(ts_list)):\n",
    "            ts_path_list.append(os.path.join(root, ts_list[i]))\n",
    "    return ts_path_list\n",
    "\n",
    "def generate_hypergraph(ts, lambd_1, lambd_2):\n",
    "    alpha_list = []\n",
    "    for i in range(ts.shape[1]):\n",
    "        X_m , A_m = gen_mtrx(ts , i)\n",
    "        alpha = couple_coeff(X_m, A_m, lambd_1 , lambd_2 )\n",
    "        alpha_list.append(alpha)\n",
    "    alpha_array = np.concatenate(alpha_list, axis=1)\n",
    "    np.fill_diagonal(alpha_array, 1)\n",
    "    assert alpha_array.shape[0] == alpha_array.shape[1]\n",
    "    return alpha_array\n",
    "\n",
    "def threshold_hypergraph(hypergraph, threshold):\n",
    "    for i in range(hypergraph.shape[0]):\n",
    "        for j in range(hypergraph.shape[1]):\n",
    "            if abs(hypergraph[i,j]) < threshold:\n",
    "                hypergraph[i , j] = 0\n",
    "            else:\n",
    "                hypergraph[i , j] = 1\n",
    "    return hypergraph\n",
    "\n",
    "def save_hypergraph(hypergraph,directory,method,threshold,lambd_1, lambd_2,id):\n",
    "    dir = f'{directory}/{method}/thresh_{threshold}_lambda_1_{lambd_1}_lambda_2_{lambd_2}'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    np.savetxt(f'{dir}/{id}_{method}_{threshold}.csv', hypergraph, delimiter=',')\n",
    "    return\n",
    "\n",
    "def train_test_split(X_m , A_m, train_pct):\n",
    "    dims = A_m.shape\n",
    "    train_pct = train_pct\n",
    "    train_split = int(train_pct * dims[0])\n",
    "    X_train = X_m[:train_split]\n",
    "    X_test = X_m[train_split:]\n",
    "    A_train = A_m[:train_split, :]\n",
    "    A_test = A_m[train_split:, :]\n",
    "    return X_train, X_test, A_train, A_test\n",
    "\n",
    "time_series_list = time_series_loader('ADNI_gsr/time_series')\n",
    "id = time_series_list[15][-14:-4]\n",
    "time_series = np.loadtxt(time_series_list[0], delimiter=',')\n",
    "minimum_error_lambda = []\n",
    "#for i in range(116):\n",
    "X_m, A_m = gen_mtrx(time_series, 78)\n",
    "X_train, X_test, A_train, A_test = train_test_split(X_m, A_m, 0.8)\n",
    "train_errors, test_errors, lambd_2_values = test_lambd_2(X_train, A_train, X_test, A_test, 1)\n",
    "#minimum_error_lambda.append(lambd_2_values[test_errors.index(min(test_errors))])\n",
    "plot_train_test_errors(train_errors, test_errors, lambd_2_values)\n",
    "#print(minimum_error_lambda)\n",
    "\n",
    "lambd_1 = 1\n",
    "lambd_2 = 0.1\n",
    "threshold = 0.5\n",
    "time_series_list = time_series_loader('ADNI_gsr/time_series')\n",
    "for i in range(len(time_series_list)):\n",
    "    id = time_series_list[i][-14:-4]\n",
    "    time_series = np.loadtxt(time_series_list[i], delimiter=',')\n",
    "    hg = generate_hypergraph(time_series, lambd_1, lambd_2)\n",
    "    hg_thresh = threshold_hypergraph(hg, threshold)\n",
    "    save_hypergraph( hg_thresh , 'ADNI_gsr/hypergraphs' , 'elastic_net' ,threshold, lambd_1 , lambd_2, id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimers-cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

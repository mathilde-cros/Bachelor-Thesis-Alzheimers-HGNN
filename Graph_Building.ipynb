{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.convert_matrix import from_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of lists of paths to the correlation matrices for each method. Each list in the dictionary represents a different method.\n",
    "methods = ['pearson', 'spearman', 'kendall', 'partial']\n",
    "full_corr_path_lists = {}\n",
    "for method in methods:\n",
    "    method_dir = f'ADNI_full/corr_matrices/corr_matrix_{method}/'\n",
    "    full_corr_path_lists[method] = []\n",
    "    for file in os.listdir(method_dir):\n",
    "        full_corr_path_lists[method].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the diagnostic file from the diagnostic_label.csv file\n",
    "diagnostic_label = np.loadtxt('ADNI_full/diagnostic_label.csv', dtype=str, delimiter=',')\n",
    "\n",
    "# Combining the 'EMCI', 'LMCI' and 'MCI' diagnostics into a single 'MCI' label for simplicity, then one-hot encoding the diagnostics\n",
    "for patient in range(len(diagnostic_label)):\n",
    "    if diagnostic_label[patient] == 'CN':\n",
    "        diagnostic_label[patient] = 0\n",
    "    elif diagnostic_label[patient] == 'SMC':\n",
    "        diagnostic_label[patient] = 1\n",
    "    elif diagnostic_label[patient] == 'EMCI' or diagnostic_label[patient] == 'LMCI' or diagnostic_label[patient] == 'MCI':\n",
    "        diagnostic_label[patient] = 2\n",
    "    elif diagnostic_label[patient] == 'AD':\n",
    "        diagnostic_label[patient] = 3\n",
    "    else:\n",
    "        print('Error: Diagnostic label not recognised')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the age feature of patients to use as a node feature\n",
    "ages = np.loadtxt('ADNI_full/age.csv', delimiter=',')\n",
    "min_age = np.min(ages)\n",
    "max_age = np.max(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing the sex feature of patients to use as a node feature. Here, 0 represents male patients and 1 represents female patients\n",
    "sex = np.loadtxt('ADNI_full/sex.csv', dtype=str, delimiter=',')\n",
    "for patient in range(len(sex)):\n",
    "    if sex[patient] == 'M':\n",
    "        sex[patient] = 0\n",
    "    else:\n",
    "        sex[patient] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'full_corr_path_lists' (dict)\n",
      "Stored 'diagnostic_label' (ndarray)\n",
      "Stored 'ages' (ndarray)\n",
      "Stored 'min_age' (float64)\n",
      "Stored 'max_age' (float64)\n",
      "Stored 'sex' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "# To be able to access these variables from other notebooks\n",
    "%store full_corr_path_lists\n",
    "%store diagnostic_label\n",
    "%store ages\n",
    "%store min_age\n",
    "%store max_age\n",
    "%store sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to simplify the code in the class Raw_to_Graph.\n",
    "\n",
    "# To convert a dictionnary into a numpy array\n",
    "def dict_to_array(dict):\n",
    "    array = np.array(list(dict.values()))\n",
    "    return array\n",
    "\n",
    "# To normalize an array\n",
    "def normalize_array(array):\n",
    "    norm_array = (array - np.mean(array)) / np.std(array)\n",
    "    return norm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a class to preprocess raw data into a format suitable for training Graph Neural Networks (GNNs).\n",
    "## With the possibility of assigning weight to edges.\n",
    "\n",
    "class Raw_to_Graph(InMemoryDataset):\n",
    "    def __init__(self, root, threshold, method, weight, transform=None, pre_transform=None):\n",
    "        self.threshold = threshold\n",
    "        self.method = method\n",
    "        self.weight = weight\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    # This function is used to process the raw data into a format suitable for GNNs, by constructing graphs out of the connectivity matrices.\n",
    "    def process(self):\n",
    "        graphs=[]\n",
    "        corr_matrices = full_corr_path_lists[self.method]\n",
    "        for patient_idx, patient_matrix in enumerate(corr_matrices):\n",
    "            path = f'ADNI_full/corr_matrices/corr_matrix_{self.method}/{patient_matrix}'\n",
    "            corr_matrix = pd.read_csv(path, header=None).values\n",
    "            # Here ROIs stands for Regions of Interest\n",
    "            nbr_ROIs = corr_matrix.shape[0]\n",
    "            edge_matrix = np.zeros((nbr_ROIs,nbr_ROIs))\n",
    "            for j in range(nbr_ROIs):\n",
    "                for k in range(nbr_ROIs):\n",
    "                    # Here we are using the absolute value of each element of the correlation matrix, as the corr coeff is in the range [-1,1].\n",
    "                    if np.abs(corr_matrix[ j , k ]) < self.threshold:\n",
    "                        edge_matrix[ j , k ] = 0\n",
    "                    else:\n",
    "                        if self.weight:\n",
    "                            # Here we assign the absolute value of the correlation coefficient as the edge weight.\n",
    "                            edge_matrix[ j , k ] = corr_matrix[ j , k]\n",
    "                        else:\n",
    "                            # Here we assign 1 as the edge weight, i.e. regardless of the the absolute value of the correlation coefficient.\n",
    "                            edge_matrix[ j , k ] = 1\n",
    "\n",
    "            # Create a NetworkX graph from the edge matrix\n",
    "            NetworkX_graph = from_numpy_array(edge_matrix)\n",
    "\n",
    "            # Compute the degree, betweenness centrality, clustering coefficient, local efficiency for each node of the graph and the global efficiency of the graph\n",
    "            degree_dict = dict(NetworkX_graph.degree())\n",
    "            between_central_dict = nx.betweenness_centrality(NetworkX_graph)\n",
    "            cluster_coeff_dict = nx.clustering(NetworkX_graph)\n",
    "            global_eff = nx.global_efficiency(NetworkX_graph)\n",
    "            local_eff_dict = {}\n",
    "            for node in NetworkX_graph.nodes():\n",
    "                subgraph_neighb = NetworkX_graph.subgraph(NetworkX_graph.neighbors(node))\n",
    "                if subgraph_neighb.number_of_nodes() > 1:\n",
    "                    efficiency = nx.global_efficiency(subgraph_neighb)\n",
    "                else:\n",
    "                    efficiency = 0.0\n",
    "                local_eff_dict[node] = efficiency\n",
    "\n",
    "            # Convert the degree, betweenness centrality, local efficiency, clustering coefficient and ratio of local to global efficiency dictionaries to NumPy arrays then normalize them\n",
    "            degree_array = dict_to_array(degree_dict)\n",
    "            degree_array_norm = normalize_array(degree_array)\n",
    "\n",
    "            between_central_array = dict_to_array(between_central_dict)\n",
    "            between_central_array_norm = normalize_array(between_central_array)\n",
    "\n",
    "            local_efficiency_array = dict_to_array(local_eff_dict)\n",
    "            local_eff_array_norm = normalize_array(local_efficiency_array)\n",
    "\n",
    "            ratio_local_global_array = dict_to_array(local_eff_dict) / global_eff\n",
    "            ratio_local_global_array_norm = normalize_array(ratio_local_global_array)\n",
    "\n",
    "            cluster_coeff_array = dict_to_array(cluster_coeff_dict)\n",
    "            cluster_coeff_array_norm = normalize_array(cluster_coeff_array)\n",
    "            \n",
    "            # Extracting the age and sex features of the patient\n",
    "            patient_age = ages[patient_idx]\n",
    "            age_norm = (patient_age - min_age) / (max_age - min_age)\n",
    "            patient_sex = int(sex[patient_idx])\n",
    "            # Making the age and sex arrays the same size as the other arrays\n",
    "            age_array = np.full((nbr_ROIs,), age_norm)\n",
    "            sex_array = np.full((nbr_ROIs,), patient_sex)\n",
    "\n",
    "            # Concatenate the degree, participation coefficient, betweenness centrality, local efficiency, and ratio of local to global efficiency arrays to form a single feature vector\n",
    "            x_conc = torch.tensor(np.concatenate((degree_array_norm, between_central_array_norm, local_eff_array_norm, cluster_coeff_array_norm, ratio_local_global_array_norm, age_array, sex_array)), dtype=torch.float)\n",
    "            # Determining the number of features concatenated to reshape with the correct dimensions\n",
    "            x = torch.reshape(x_conc, (7, nbr_ROIs)).T\n",
    "\n",
    "            # Create a Pytorch Geometric Data object from the NetworkX \n",
    "            graph_data = from_networkx(NetworkX_graph)\n",
    "            ## The feature matrix of the graph is the degree, betweenness centrality, local efficiency, clustering coefficient and ratio of local to global efficiency of each node\n",
    "            graph_data.x = x\n",
    "            ## The target/output variable that we want to predict is the diagnostic label of the patient\n",
    "            graph_data.y = diagnostic_label[patient_idx]\n",
    "            graphs.append(graph_data)\n",
    "\n",
    "        data, slices = self.collate(graphs)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_features_and_stats(dataset):\n",
    "    print()\n",
    "    print(f'Dataset: {dataset}:')\n",
    "    print('====================')\n",
    "    print(f'Number of graphs: {len(dataset)}')\n",
    "    print(f'Weighted: {dataset.weight}')\n",
    "    print(f'Threshold: {dataset.threshold}')\n",
    "    print(f'Correlation Method: {dataset.method}')\n",
    "    print(f'Number of features: {dataset.num_features}')\n",
    "    print(f'Number of classes: {len(np.unique(diagnostic_label))}')\n",
    "\n",
    "    # Getting the first graph object in the dataset.\n",
    "    data = dataset[0]\n",
    "\n",
    "    print()\n",
    "    print(data)\n",
    "    print('=============================================================')\n",
    "\n",
    "    # Some statistics about the first graph.\n",
    "    print(f'Number of nodes: {data.num_nodes}')\n",
    "    print(f'Number of edges: {data.num_edges}')\n",
    "    print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "    print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "    print(f'Has self-loops: {data.has_self_loops()}')\n",
    "    print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: False\n",
      "Threshold: 0.4\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 2008], weight=[2008], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 2008\n",
      "Average node degree: 17.31\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "weight = False\n",
    "method = 'pearson'\n",
    "\n",
    "root = f'Raw_to_graph/ADNI_T_{threshold}_W_{weight}_M_{method}'\n",
    "dataset = Raw_to_Graph(root=root, threshold=threshold, method=method, weight=weight)\n",
    "dataset_features_and_stats(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.1\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 9700], weight=[9700], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 9700\n",
      "Average node degree: 83.62\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.2\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 6570], weight=[6570], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 6570\n",
      "Average node degree: 56.64\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.3\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 3938], weight=[3938], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 3938\n",
      "Average node degree: 33.95\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.4\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 2008], weight=[2008], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 2008\n",
      "Average node degree: 17.31\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.5\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 1000], weight=[1000], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 1000\n",
      "Average node degree: 8.62\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.6\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 456], weight=[456], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 456\n",
      "Average node degree: 3.93\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "Done!\n",
      "Processing...\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Raw_to_Graph(197):\n",
      "====================\n",
      "Number of graphs: 197\n",
      "Weighted: True\n",
      "Threshold: 0.7\n",
      "Correlation Method: pearson\n",
      "Number of features: 7\n",
      "Number of classes: 4\n",
      "\n",
      "Data(edge_index=[2, 190], weight=[190], x=[116, 7], y='0', num_nodes=116)\n",
      "=============================================================\n",
      "Number of nodes: 116\n",
      "Number of edges: 190\n",
      "Average node degree: 1.64\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1490021299.py:66: RuntimeWarning: invalid value encountered in divide\n",
      "  ratio_local_global_array = dict_to_array(local_eff_dict) / global_eff\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n",
      "/var/folders/wh/snjqmpvj7qv64q1ngy8zvqbh0000gn/T/ipykernel_99747/1420994389.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_array = (array - np.mean(array)) / np.std(array)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[1;32m      9\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRaw_to_graph/ADNI_T_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_W_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_M_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mRaw_to_Graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     dataset_features_and_stats(dataset)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mRaw_to_Graph.__init__\u001b[0;34m(self, root, threshold, method, weight, transform, pre_transform)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m=\u001b[39m method\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m weight\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:76\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     log: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m ):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/dataset.py:102\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/dataset.py:235\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    234\u001b[0m makedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    238\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[0;32mIn[8], line 93\u001b[0m, in \u001b[0;36mRaw_to_Graph.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m     graph_data\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m diagnostic_label[patient_idx]\n\u001b[1;32m     91\u001b[0m     graphs\u001b[38;5;241m.\u001b[39mappend(graph_data)\n\u001b[0;32m---> 93\u001b[0m data, slices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m torch\u001b[38;5;241m.\u001b[39msave((data, slices), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:139\u001b[0m, in \u001b[0;36mInMemoryDataset.collate\u001b[0;34m(data_list)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_list[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m data, slices, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, slices\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/collate.py:78\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m exclude_keys:  \u001b[38;5;66;03m# Do not include top-level attribute.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# The `num_nodes` attribute needs special treatment, as we need to\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# sum their values up instead of merging them to a list:\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/collate.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m exclude_keys:  \u001b[38;5;66;03m# Do not include top-level attribute.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m values \u001b[38;5;241m=\u001b[39m [\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# The `num_nodes` attribute needs special treatment, as we need to\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# sum their values up instead of merging them to a list:\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/alzheimers-cl/lib/python3.11/site-packages/torch_geometric/data/storage.py:111\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weight'"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "weights = [True, False]\n",
    "# methods = ['pearson', 'spearman', 'kendall', 'partial']\n",
    "methods = ['pearson']\n",
    "\n",
    "for weight in weights:\n",
    "    for method in methods:\n",
    "        for threshold in thresholds:\n",
    "            root = f'Raw_to_graph/ADNI_T_{threshold}_W_{weight}_M_{method}'\n",
    "            dataset = Raw_to_Graph(root=root, threshold=threshold, method=method, weight=weight)\n",
    "            dataset_features_and_stats(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alzheimers-cl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
